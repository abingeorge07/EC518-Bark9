diff --git a/__pycache__/constant.cpython-310.pyc b/__pycache__/constant.cpython-310.pyc
index 83c6cb4..a24d901 100644
Binary files a/__pycache__/constant.cpython-310.pyc and b/__pycache__/constant.cpython-310.pyc differ
diff --git a/constant.py b/constant.py
index ca1447b..89ffba6 100644
--- a/constant.py
+++ b/constant.py
@@ -1,2 +1,2 @@
-WIDTH = 1200
-HEIGHT = 900
\ No newline at end of file
+WIDTH = 320
+HEIGHT = 240
\ No newline at end of file
diff --git a/rlkit/samplers/rollout_functions.py b/rlkit/samplers/rollout_functions.py
index 9f1c0fd..620d4f2 100644
--- a/rlkit/samplers/rollout_functions.py
+++ b/rlkit/samplers/rollout_functions.py
@@ -106,6 +106,7 @@ def rollout(
     while path_length < max_path_length:
         raw_obs.append(o)
         o_for_agent = preprocess_obs_for_policy_fn(o)
+        
         a, agent_info = agent.get_action(o_for_agent, **get_action_kwargs)
 
         if full_o_postprocess_func:
diff --git a/train_racing.py b/train_racing.py
index 0c1aec4..d4b012f 100644
--- a/train_racing.py
+++ b/train_racing.py
@@ -35,17 +35,6 @@ class quadrupedEnv(gym.Env):
 
     def __init__(self, model=None):
 
-        # # Use gpu if available
-        # self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-
-        # # model
-        # self.model = model
-        # midas_transforms = torch.hub.load("intel-isl/MiDaS", "transforms")
-        # self.midas_transform = midas_transforms.small_transform
-        
-        # # move model to device
-        # self.model.to(self.device)
-
         # constants
         self.height = HEIGHT
         self.width = WIDTH
@@ -102,8 +91,8 @@ class quadrupedEnv(gym.Env):
                                        high=np.array([1.0, 1.0, 1.0]), dtype=np.float32)
         
         # Define observation space (RGB image)
-        self.observation_space = spaces.Box(low=0, high=255, shape=(self.height, self.width, 3), dtype=np.uint8)
-        self.observation = np.zeros((self.height, self.width, 3))
+        self.observation_space = spaces.Box(low=0, high=255, shape=(self.height, self.width, 1), dtype=np.uint8)
+        self.observation = np.zeros((self.height, self.width, 1))
 
     
 
@@ -157,6 +146,16 @@ class quadrupedEnv(gym.Env):
         self.scene_top = mujoco.MjvScene(self.model, maxgeom=10000)
         self.context_top = mujoco.MjrContext(self.model, mujoco.mjtFontScale.mjFONTSCALE_150.value)
 
+        # Define action space (3D vector)
+        self.action_space = spaces.Box(low=np.array([-1.0, -1.0, -1.0]), 
+                                       high=np.array([1.0, 1.0, 1.0]), dtype=np.float32)
+        
+        # Define observation space (RGB image)
+        self.observation_space = spaces.Box(low=0, high=255, shape=(self.height, self.width, 1), dtype=np.uint8)
+        self.observation = np.zeros((self.height, self.width, 1))
+
+        return self.observation
+
 
     # function to render the window (pov)
     def windowView(self, model, data, opt, camera, scene, context, window):
@@ -191,9 +190,6 @@ class quadrupedEnv(gym.Env):
 
             self.depth_image = get_height_map_from_rgb(self.rgb_buffer)
             
-
-            
-
             # # Preprocess the image
             # input_batch = self.midas_transform(self.rgb_buffer)
 
@@ -243,34 +239,107 @@ class quadrupedEnv(gym.Env):
 
         
 
-
-
-if __name__ == "__main__":
-
-    # # Load the model
-    # model_type = "MiDaS_small"  # Options: DPT_Large, DPT_Hybrid, MiDaS_small
-    # model = torch.hub.load("intel-isl/MiDaS", model_type)
+def experiment(variant):
+    expl_env = NormalizedBoxEnv(quadrupedEnv())
+    eval_env = NormalizedBoxEnv(quadrupedEnv())
+    obs_dim = expl_env.observation_space.low.size
+ 
+    action_dim = eval_env.action_space.low.size
+
+    M = variant['layer_size']
+    qf1 = ConcatMlp(
+        input_size=obs_dim + action_dim,
+        output_size=1,
+        hidden_sizes=[M, M],
+    )
+    qf2 = ConcatMlp(
+        input_size=obs_dim + action_dim,
+        output_size=1,
+        hidden_sizes=[M, M],
+    )
+    target_qf1 = ConcatMlp(
+        input_size=obs_dim + action_dim,
+        output_size=1,
+        hidden_sizes=[M, M],
+    )
+    target_qf2 = ConcatMlp(
+        input_size=obs_dim + action_dim,
+        output_size=1,
+        hidden_sizes=[M, M],
+    )
+    policy = TanhGaussianPolicy(
+        obs_dim=obs_dim,
+        action_dim=action_dim,
+        hidden_sizes=[M, M],
+    )
+    eval_policy = MakeDeterministic(policy)
+    eval_path_collector = MdpPathCollector(
+        eval_env,
+        eval_policy,
+    )
+    expl_path_collector = MdpPathCollector(
+        expl_env,
+        policy,
+    )
+    replay_buffer = EnvReplayBuffer(
+        variant['replay_buffer_size'],
+        expl_env,
+
+    )
+    trainer = SACTrainer(
+        env=eval_env,
+        policy=policy,
+        qf1=qf1,
+        qf2=qf2,
+        target_qf1=target_qf1,
+        target_qf2=target_qf2,
+        **variant['trainer_kwargs']
+    )
+    algorithm = TorchBatchRLAlgorithm(
+        trainer=trainer,
+        exploration_env=expl_env,
+        evaluation_env=eval_env,
+        exploration_data_collector=expl_path_collector,
+        evaluation_data_collector=eval_path_collector,
+        replay_buffer=replay_buffer,
+        **variant['algorithm_kwargs']
+    )
+    algorithm.to(ptu.device)
+    algorithm.train()
 
 
 
-    env = quadrupedEnv()
-    simstart = env.startSim()
-    
-    while not mujoco.glfw.glfw.window_should_close(env.window_top):
-        simstart = env.startSim()
 
-        torques = [0.1, 0.001, 0.001]
 
-        while (env.data.time - simstart < 10.0/60.0):
-            env.step()
-
-        env.render()
-        if(env.pov_working):
-            # Display the height map
-            cv2.imshow("Height Map", env.depth_mujoco)
-            # cv2.imshow("Depth Map", env.depth_map)
+if __name__ == "__main__":
+    # noinspection PyTypeChecker
+    variant = dict(
+        algorithm="SAC",
+        version="normal",
+        layer_size=256,
+        replay_buffer_size=int(1E4),
+        algorithm_kwargs=dict(
+            num_epochs=3000,
+            num_eval_steps_per_epoch=5000,
+            num_trains_per_train_loop=1000,
+            num_expl_steps_per_train_loop=1000,
+            min_num_steps_before_training=1000,
+            max_path_length=1000,
+            batch_size=256,
+        ),
+        trainer_kwargs=dict(
+            discount=0.99,
+            soft_target_tau=5e-3,
+            target_update_period=1,
+            policy_lr=3E-4,
+            qf_lr=3E-4,
+            reward_scale=1,
+            use_automatic_entropy_tuning=True,
+        ),
+    )
+    setup_logger('name-of-experiment', variant=variant)
+    # ptu.set_gpu_mode(True)  # optionally set the GPU (default=False)
+    experiment(variant)
 
-            if cv2.waitKey(1) == ord('q'):
-                break
         
     
\ No newline at end of file
