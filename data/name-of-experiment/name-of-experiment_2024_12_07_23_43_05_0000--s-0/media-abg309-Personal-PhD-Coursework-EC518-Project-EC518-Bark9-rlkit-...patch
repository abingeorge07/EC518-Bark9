diff --git a/__pycache__/constant.cpython-310.pyc b/__pycache__/constant.cpython-310.pyc
index 83c6cb4..a24d901 100644
Binary files a/__pycache__/constant.cpython-310.pyc and b/__pycache__/constant.cpython-310.pyc differ
diff --git a/constant.py b/constant.py
index ca1447b..89ffba6 100644
--- a/constant.py
+++ b/constant.py
@@ -1,2 +1,2 @@
-WIDTH = 1200
-HEIGHT = 900
\ No newline at end of file
+WIDTH = 320
+HEIGHT = 240
\ No newline at end of file
diff --git a/rlkit/samplers/rollout_functions.py b/rlkit/samplers/rollout_functions.py
index 9f1c0fd..620d4f2 100644
--- a/rlkit/samplers/rollout_functions.py
+++ b/rlkit/samplers/rollout_functions.py
@@ -106,6 +106,7 @@ def rollout(
     while path_length < max_path_length:
         raw_obs.append(o)
         o_for_agent = preprocess_obs_for_policy_fn(o)
+        
         a, agent_info = agent.get_action(o_for_agent, **get_action_kwargs)
 
         if full_o_postprocess_func:
diff --git a/rlkit/torch/core.py b/rlkit/torch/core.py
index f9b407e..991d909 100644
--- a/rlkit/torch/core.py
+++ b/rlkit/torch/core.py
@@ -60,7 +60,7 @@ def elem_or_tuple_to_numpy(elem_or_tuple):
 
 def _filter_batch(np_batch):
     for k, v in np_batch.items():
-        if v.dtype == np.bool:
+        if v.dtype == bool:
             yield k, v.astype(int)
         else:
             yield k, v
diff --git a/train_racing.py b/train_racing.py
index 0c1aec4..6a05acc 100644
--- a/train_racing.py
+++ b/train_racing.py
@@ -35,17 +35,6 @@ class quadrupedEnv(gym.Env):
 
     def __init__(self, model=None):
 
-        # # Use gpu if available
-        # self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-
-        # # model
-        # self.model = model
-        # midas_transforms = torch.hub.load("intel-isl/MiDaS", "transforms")
-        # self.midas_transform = midas_transforms.small_transform
-        
-        # # move model to device
-        # self.model.to(self.device)
-
         # constants
         self.height = HEIGHT
         self.width = WIDTH
@@ -102,8 +91,8 @@ class quadrupedEnv(gym.Env):
                                        high=np.array([1.0, 1.0, 1.0]), dtype=np.float32)
         
         # Define observation space (RGB image)
-        self.observation_space = spaces.Box(low=0, high=255, shape=(self.height, self.width, 3), dtype=np.uint8)
-        self.observation = np.zeros((self.height, self.width, 3))
+        self.observation_space = spaces.Box(low=0, high=255, shape=(self.height, self.width, 1), dtype=np.uint8)
+        self.observation = np.zeros((self.height, self.width, 1))
 
     
 
@@ -157,6 +146,19 @@ class quadrupedEnv(gym.Env):
         self.scene_top = mujoco.MjvScene(self.model, maxgeom=10000)
         self.context_top = mujoco.MjrContext(self.model, mujoco.mjtFontScale.mjFONTSCALE_150.value)
 
+        # Define action space (3D vector)
+        self.action_space = spaces.Box(low=np.array([-1.0, -1.0, -1.0]), 
+                                       high=np.array([1.0, 1.0, 1.0]), dtype=np.float32)
+        
+        # Define observation space (RGB image)
+        self.observation_space = spaces.Box(low=0, high=255, shape=(self.height, self.width, 1), dtype=np.uint8)
+        self.observation = np.zeros((self.height, self.width, 1))
+
+        tensor_observation = torch.tensor(self.observation, dtype=torch.float32)  # Convert to tensor
+        tensor_observation = tensor_observation.view(1, -1)
+
+        return tensor_observation
+
 
     # function to render the window (pov)
     def windowView(self, model, data, opt, camera, scene, context, window):
@@ -177,54 +179,44 @@ class quadrupedEnv(gym.Env):
 
     # Used to view the environment
     def render(self):
-        if(self.pov_working):
- 
-            self.windowView(self.model, self.data, self.opt, self.camera, self.scene, self.context, self.window)
-            
-            # Get the height map 
-            self.depth_mujoco, self.rgb_buffer = get_height_map(self.model, self.data, self.camera, self.scene, self.context, self.window)
-
 
-            # image = cv2.imread("image.png")  # OpenCV loads as BGR
+        simstart = self.startSim()
 
-            # self.rgb_buffer = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
+        while (self.data.time - simstart < 1.0/60.0):
+            mujoco.mj_step(self.model, self.data)
 
-            self.depth_image = get_height_map_from_rgb(self.rgb_buffer)
-            
-
-            
-
-            # # Preprocess the image
-            # input_batch = self.midas_transform(self.rgb_buffer)
+        if(self.pov_working):
 
-            # # Move to device
-            # input_batch = input_batch.to(self.device)
+            self.windowView(self.model, self.data, self.opt, self.camera, self.scene, self.context, self.window)
 
+            # Get the height map 
+            self.depth_mujoco, self.rgb_buffer = get_height_map(self.model, self.data, self.camera, self.scene, self.context, self.window)
 
-            # # Get the depth map
-            # # Perform depth estimation
-            # with torch.no_grad():
-            #     prediction = model(input_batch)
+            self.depth_image = get_height_map_from_rgb(self.rgb_buffer)
 
-            #     prediction = torch.nn.functional.interpolate(
-            #         prediction.unsqueeze(1),
-            #         size=[self.height, self.width],
-            #         mode="bicubic",
-            #         align_corners=False,
-            #     ).squeeze()
+            # Display the height map
+            cv2.imshow("Height Map", self.depth_image)
 
-            # depth_map = prediction.cpu().numpy()  # Remove batch dimension and convert to NumPy
-            
-            # self.depth_map = depth_map
+            # image = cv2.imread("image.png")  # OpenCV loads as BGR
 
 
         ## WINDOW 2 ##
         self.windowView(self.model, self.data, self.opt, self.camera_top, self.scene_top, self.context_top, self.window_top)
 
     # Used to do a step in the environment
-    def step(self):
-        mujoco.mj_step(self.model, self.data)
+    def step(self, action=None):
+        if(action is not None):
+            self.setTorques(action)
+        
+        self.render()
+
+
+        # Get the observation
+        depthImage = self.depth_image.copy()
+        tensor_observation = torch.tensor(depthImage, dtype=torch.float32)  # Convert to tensor
+        tensor_observation = tensor_observation.view(1, -1)
 
+        return tensor_observation, 0, False, {}
 
     # Start sim time
     def startSim(self):
@@ -243,34 +235,135 @@ class quadrupedEnv(gym.Env):
 
         
 
+def experiment(variant):
+    expl_env = NormalizedBoxEnv(quadrupedEnv())
+    eval_env = NormalizedBoxEnv(quadrupedEnv())
+    obs_dim = expl_env.observation_space.low.size
+ 
+    action_dim = eval_env.action_space.low.size
+
+    M = variant['layer_size']
+    qf1 = ConcatMlp(
+        input_size=obs_dim + action_dim,
+        output_size=1,
+        hidden_sizes=[M, M],
+    )
+    qf2 = ConcatMlp(
+        input_size=obs_dim + action_dim,
+        output_size=1,
+        hidden_sizes=[M, M],
+    )
+    target_qf1 = ConcatMlp(
+        input_size=obs_dim + action_dim,
+        output_size=1,
+        hidden_sizes=[M, M],
+    )
+    target_qf2 = ConcatMlp(
+        input_size=obs_dim + action_dim,
+        output_size=1,
+        hidden_sizes=[M, M],
+    )
+    policy = TanhGaussianPolicy(
+        obs_dim=obs_dim,
+        action_dim=action_dim,
+        hidden_sizes=[M, M],
+    )
+    eval_policy = MakeDeterministic(policy)
+    eval_path_collector = MdpPathCollector(
+        eval_env,
+        eval_policy,
+    )
+    expl_path_collector = MdpPathCollector(
+        expl_env,
+        policy,
+    )
+    replay_buffer = EnvReplayBuffer(
+        variant['replay_buffer_size'],
+        expl_env,
+
+    )
+    trainer = SACTrainer(
+        env=eval_env,
+        policy=policy,
+        qf1=qf1,
+        qf2=qf2,
+        target_qf1=target_qf1,
+        target_qf2=target_qf2,
+        **variant['trainer_kwargs']
+    )
+    algorithm = TorchBatchRLAlgorithm(
+        trainer=trainer,
+        exploration_env=expl_env,
+        evaluation_env=eval_env,
+        exploration_data_collector=expl_path_collector,
+        evaluation_data_collector=eval_path_collector,
+        replay_buffer=replay_buffer,
+        **variant['algorithm_kwargs']
+    )
+    algorithm.to(ptu.device)
+    algorithm.train()
 
 
-if __name__ == "__main__":
 
-    # # Load the model
-    # model_type = "MiDaS_small"  # Options: DPT_Large, DPT_Hybrid, MiDaS_small
-    # model = torch.hub.load("intel-isl/MiDaS", model_type)
 
 
-
-    env = quadrupedEnv()
-    simstart = env.startSim()
+if __name__ == "__main__":
+    # noinspection PyTypeChecker
+    variant = dict(
+        algorithm="SAC",
+        version="normal",
+        layer_size=256,
+        replay_buffer_size=int(1E4),
+        algorithm_kwargs=dict(
+            num_epochs=3000,
+            num_eval_steps_per_epoch=5000,
+            num_trains_per_train_loop=1000,
+            num_expl_steps_per_train_loop=1000,
+            min_num_steps_before_training=1000,
+            max_path_length=1000,
+            batch_size=256,
+        ),
+        trainer_kwargs=dict(
+            discount=0.99,
+            soft_target_tau=5e-3,
+            target_update_period=1,
+            policy_lr=3E-4,
+            qf_lr=3E-4,
+            reward_scale=1,
+            use_automatic_entropy_tuning=True,
+        ),
+    )
+    setup_logger('name-of-experiment', variant=variant)
+    # ptu.set_gpu_mode(True)  # optionally set the GPU (default=False)
+    experiment(variant)
+
+
+
+# if __name__ == "__main__":
+
+# # # Load the model
+# # model_type = "MiDaS_small"  # Options: DPT_Large, DPT_Hybrid, MiDaS_small
+# # model = torch.hub.load("intel-isl/MiDaS", model_type)
+
+
+
+#     env = quadrupedEnv()
     
-    while not mujoco.glfw.glfw.window_should_close(env.window_top):
-        simstart = env.startSim()
+#     while not mujoco.glfw.glfw.window_should_close(env.window_top):
+#         simstart = env.startSim()
 
-        torques = [0.1, 0.001, 0.001]
+#         torques = [0.1, 0.001, 0.001]
 
-        while (env.data.time - simstart < 10.0/60.0):
-            env.step()
+#         while (env.data.time - simstart < 10.0/60.0):
+#             env.step()
 
-        env.render()
-        if(env.pov_working):
-            # Display the height map
-            cv2.imshow("Height Map", env.depth_mujoco)
-            # cv2.imshow("Depth Map", env.depth_map)
+#         env.render()
+#         if(env.pov_working):
+#             # Display the height map
+#             cv2.imshow("Height Map", env.depth_mujoco)
+#             # cv2.imshow("Depth Map", env.depth_map)
 
-            if cv2.waitKey(1) == ord('q'):
-                break
-        
+#             if cv2.waitKey(1) == ord('q'):
+#                 break
+           
     
\ No newline at end of file
