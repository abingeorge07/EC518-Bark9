diff --git a/__pycache__/constant.cpython-310.pyc b/__pycache__/constant.cpython-310.pyc
index 83c6cb4..a24d901 100644
Binary files a/__pycache__/constant.cpython-310.pyc and b/__pycache__/constant.cpython-310.pyc differ
diff --git a/constant.py b/constant.py
index ca1447b..89ffba6 100644
--- a/constant.py
+++ b/constant.py
@@ -1,2 +1,2 @@
-WIDTH = 1200
-HEIGHT = 900
\ No newline at end of file
+WIDTH = 320
+HEIGHT = 240
\ No newline at end of file
diff --git a/rlkit/samplers/rollout_functions.py b/rlkit/samplers/rollout_functions.py
index 9f1c0fd..620d4f2 100644
--- a/rlkit/samplers/rollout_functions.py
+++ b/rlkit/samplers/rollout_functions.py
@@ -106,6 +106,7 @@ def rollout(
     while path_length < max_path_length:
         raw_obs.append(o)
         o_for_agent = preprocess_obs_for_policy_fn(o)
+        
         a, agent_info = agent.get_action(o_for_agent, **get_action_kwargs)
 
         if full_o_postprocess_func:
diff --git a/rlkit/torch/core.py b/rlkit/torch/core.py
index f9b407e..991d909 100644
--- a/rlkit/torch/core.py
+++ b/rlkit/torch/core.py
@@ -60,7 +60,7 @@ def elem_or_tuple_to_numpy(elem_or_tuple):
 
 def _filter_batch(np_batch):
     for k, v in np_batch.items():
-        if v.dtype == np.bool:
+        if v.dtype == bool:
             yield k, v.astype(int)
         else:
             yield k, v
diff --git a/train_racing.py b/train_racing.py
index 0c1aec4..0599f95 100644
--- a/train_racing.py
+++ b/train_racing.py
@@ -35,17 +35,6 @@ class quadrupedEnv(gym.Env):
 
     def __init__(self, model=None):
 
-        # # Use gpu if available
-        # self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
-
-        # # model
-        # self.model = model
-        # midas_transforms = torch.hub.load("intel-isl/MiDaS", "transforms")
-        # self.midas_transform = midas_transforms.small_transform
-        
-        # # move model to device
-        # self.model.to(self.device)
-
         # constants
         self.height = HEIGHT
         self.width = WIDTH
@@ -76,86 +65,106 @@ class quadrupedEnv(gym.Env):
         # Initialize the viewer
         mujoco.glfw.glfw.init()
 
+        mujoco.mj_resetDataKeyframe(self.model, self.data, 0)
 
-        if(self.pov_working):
-            # Create a window
-            self.window = mujoco.glfw.glfw.create_window(self.width, self.height, "POV", None, None)
-            # make the context current
-            mujoco.glfw.glfw.make_context_current(self.window)
-            mujoco.glfw.glfw.swap_interval(1)
-            # Create a scene and context
-            self.scene = mujoco.MjvScene(self.model, maxgeom=10000)
-            self.context = mujoco.MjrContext(self.model, mujoco.mjtFontScale.mjFONTSCALE_150.value)
+        # if(self.pov_working):
+        #     # Create a window
+        #     self.window = mujoco.glfw.glfw.create_window(self.width, self.height, "POV", None, None)
+        #     # make the context current
+        #     mujoco.glfw.glfw.make_context_current(self.window)
+        #     mujoco.glfw.glfw.swap_interval(1)
+        #     # Create a scene and context
+        #     self.scene = mujoco.MjvScene(self.model, maxgeom=10000)
+        #     self.context = mujoco.MjrContext(self.model, mujoco.mjtFontScale.mjFONTSCALE_150.value)
 
 
-        self.window_top = mujoco.glfw.glfw.create_window(self.width, self.height, "Top-Down", None, None)
-        mujoco.glfw.glfw.make_context_current(self.window_top)
-        mujoco.glfw.glfw.swap_interval(1)
 
-        self.scene_top = mujoco.MjvScene(self.model, maxgeom=10000)
-        self.context_top = mujoco.MjrContext(self.model, mujoco.mjtFontScale.mjFONTSCALE_150.value)
+        # self.window_top = mujoco.glfw.glfw.create_window(self.width, self.height, "Top-Down", None, None)
+        # mujoco.glfw.glfw.make_context_current(self.window_top)
+        # mujoco.glfw.glfw.swap_interval(1)
+
+        # self.scene_top = mujoco.MjvScene(self.model, maxgeom=10000)
+        # self.context_top = mujoco.MjrContext(self.model, mujoco.mjtFontScale.mjFONTSCALE_150.value)
 
 
     
-        # Define action space (3D vector)
+        # # Define action space (3D vector)
         self.action_space = spaces.Box(low=np.array([-1.0, -1.0, -1.0]), 
                                        high=np.array([1.0, 1.0, 1.0]), dtype=np.float32)
         
         # Define observation space (RGB image)
-        self.observation_space = spaces.Box(low=0, high=255, shape=(self.height, self.width, 3), dtype=np.uint8)
-        self.observation = np.zeros((self.height, self.width, 3))
+        self.observation_space = spaces.Box(low=0, high=255, shape=(self.height, self.width, 1), dtype=np.uint8)
+        self.observation = np.zeros((self.height, self.width, 1))
 
     
 
 
     def reset(self):
 
-        # Reset the model
-        mujoco.glfw.glfw.terminate()
-
-        # Load the model and data
-        self.model = mujoco.MjModel.from_xml_path(patriq)
-        self.data = mujoco.MjData(self.model)
-        self.opt = mujoco.MjvOption()
+        # # # Reset the model
+        # mujoco.glfw.glfw.terminate()
 
-        # Set the camera for the renderer
-        self.camera_top = mujoco.MjvCamera()
+        # # Done with simulation 
+        # self.done = False
 
-        camera_id = mujoco.mj_name2id(self.model, mujoco.mjtObj.mjOBJ_CAMERA, "main_camera")
-    
-        if(camera_id < 0):
-            # Set the camera for the viewer (onboard)
-            self.camera = mujoco.MjvCamera()
-            self.pov_working = False
-        else:
-            # Set the camera for the viewer (onboard)
-            self.camera = mujoco.MjvCamera()
-            self.camera.type = mujoco.mjtCamera.mjCAMERA_FIXED
-            self.camera.fixedcamid = camera_id
-            self.pov_working = True
+        # # Load the model and data
+        # self.model = mujoco.MjModel.from_xml_path(patriq)
+        # self.data = mujoco.MjData(self.model)
+        # self.opt = mujoco.MjvOption()
 
+        # # Set the camera for the renderer
+        # self.camera_top = mujoco.MjvCamera()
 
-        # Initialize the viewer
-        mujoco.glfw.glfw.init()
-
-
-        if(self.pov_working):
-            # Create a window
-            self.window = mujoco.glfw.glfw.create_window(self.width, self.height, "POV", None, None)
-            # make the context current
-            mujoco.glfw.glfw.make_context_current(self.window)
-            mujoco.glfw.glfw.swap_interval(1)
-            # Create a scene and context
-            self.scene = mujoco.MjvScene(self.model, maxgeom=10000)
-            self.context = mujoco.MjrContext(self.model, mujoco.mjtFontScale.mjFONTSCALE_150.value)
-
+        # camera_id = mujoco.mj_name2id(self.model, mujoco.mjtObj.mjOBJ_CAMERA, "main_camera")
+    
+        # if(camera_id < 0):
+        #     # Set the camera for the viewer (onboard)
+        #     self.camera = mujoco.MjvCamera()
+        #     self.pov_working = False
+        # else:
+        #     # Set the camera for the viewer (onboard)
+        #     self.camera = mujoco.MjvCamera()
+        #     self.camera.type = mujoco.mjtCamera.mjCAMERA_FIXED
+        #     self.camera.fixedcamid = camera_id
+        #     self.pov_working = True
+
+
+        # # # Initialize the viewer
+        # mujoco.glfw.glfw.init()
+
+
+        # if(self.pov_working):
+        #     # Create a window
+        #     self.window = mujoco.glfw.glfw.create_window(self.width, self.height, "POV", None, None)
+        #     # make the context current
+        #     mujoco.glfw.glfw.make_context_current(self.window)
+        #     mujoco.glfw.glfw.swap_interval(1)
+        #     # Create a scene and context
+        #     self.scene = mujoco.MjvScene(self.model, maxgeom=10000)
+        #     self.context = mujoco.MjrContext(self.model, mujoco.mjtFontScale.mjFONTSCALE_150.value)
+
+
+        # self.window_top = mujoco.glfw.glfw.create_window(self.width, self.height, "Top-Down", None, None)
+        # mujoco.glfw.glfw.make_context_current(self.window_top)
+        # mujoco.glfw.glfw.swap_interval(1)
+
+        # self.scene_top = mujoco.MjvScene(self.model, maxgeom=10000)
+        # self.context_top = mujoco.MjrContext(self.model, mujoco.mjtFontScale.mjFONTSCALE_150.value)
+
+        # # Define action space (3D vector)
+        # self.action_space = spaces.Box(low=np.array([-1.0, -1.0, -1.0]), 
+        #                                high=np.array([1.0, 1.0, 1.0]), dtype=np.float32)
+        
+        # Define observation space (RGB image)
+        # self.observation_space = spaces.Box(low=0, high=255, shape=(self.height, self.width, 1), dtype=np.uint8)
+        self.data = mujoco.MjData(self.model)
+        mujoco.mj_resetDataKeyframe(self.model, self.data, 0)
+        self.observation = np.zeros((self.height, self.width, 1))
 
-        self.window_top = mujoco.glfw.glfw.create_window(self.width, self.height, "Top-Down", None, None)
-        mujoco.glfw.glfw.make_context_current(self.window_top)
-        mujoco.glfw.glfw.swap_interval(1)
+        tensor_observation = torch.tensor(self.observation, dtype=torch.float32)  # Convert to tensor
+        tensor_observation = tensor_observation.view(1, -1)
 
-        self.scene_top = mujoco.MjvScene(self.model, maxgeom=10000)
-        self.context_top = mujoco.MjrContext(self.model, mujoco.mjtFontScale.mjFONTSCALE_150.value)
+        return tensor_observation
 
 
     # function to render the window (pov)
@@ -177,55 +186,56 @@ class quadrupedEnv(gym.Env):
 
     # Used to view the environment
     def render(self):
-        if(self.pov_working):
- 
-            self.windowView(self.model, self.data, self.opt, self.camera, self.scene, self.context, self.window)
-            
-            # Get the height map 
-            self.depth_mujoco, self.rgb_buffer = get_height_map(self.model, self.data, self.camera, self.scene, self.context, self.window)
 
+        simstart = self.startSim()
 
-            # image = cv2.imread("image.png")  # OpenCV loads as BGR
+        while (self.data.time - simstart < 1.0/60.0):
+            mujoco.mj_step(self.model, self.data)
+            mujoco.mj_kinematics(self.model, self.data) 
 
-            # self.rgb_buffer = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
+        # if(self.pov_working):
 
-            self.depth_image = get_height_map_from_rgb(self.rgb_buffer)
-            
+        #     self.windowView(self.model, self.data, self.opt, self.camera, self.scene, self.context, self.window)
 
-            
+        #     # Get the height map 
+        #     self.depth_mujoco, self.rgb_buffer = get_height_map(self.model, self.data, self.camera, self.scene, self.context, self.window)
 
-            # # Preprocess the image
-            # input_batch = self.midas_transform(self.rgb_buffer)
+        #     self.depth_image = get_height_map_from_rgb(self.rgb_buffer)
 
-            # # Move to device
-            # input_batch = input_batch.to(self.device)
+        #     # Display the height map
+        #     cv2.imshow("Height Map", self.depth_image)
+        #     cv2.waitKey(1)
 
 
-            # # Get the depth map
-            # # Perform depth estimation
-            # with torch.no_grad():
-            #     prediction = model(input_batch)
+        # ## WINDOW 2 ##
+        # self.windowView(self.model, self.data, self.opt, self.camera_top, self.scene_top, self.context_top, self.window_top)
 
-            #     prediction = torch.nn.functional.interpolate(
-            #         prediction.unsqueeze(1),
-            #         size=[self.height, self.width],
-            #         mode="bicubic",
-            #         align_corners=False,
-            #     ).squeeze()
+    # Used to do a step in the environment
+    def step(self, action=None):
+        if(action is not None):
+            self.setTorques(action)
+        
+        self.render()
 
-            # depth_map = prediction.cpu().numpy()  # Remove batch dimension and convert to NumPy
-            
-            # self.depth_map = depth_map
+        print(self.data.time)
+        if(self.data.time > 20.0):
+            self.done = True
+        else:
+            self.done = False
 
+        # Get the observation
+        depthImage = self.depth_image.copy()
+        tensor_observation = torch.tensor(depthImage, dtype=torch.float32)  # Convert to tensor
+        tensor_observation = tensor_observation.view(1, -1)
 
-        ## WINDOW 2 ##
-        self.windowView(self.model, self.data, self.opt, self.camera_top, self.scene_top, self.context_top, self.window_top)
+        # Get the reward
+        reward = self.findReward()
 
-    # Used to do a step in the environment
-    def step(self):
-        mujoco.mj_step(self.model, self.data)
+        # print(reward)
 
 
+        return tensor_observation, reward, self.done, {}
+
     # Start sim time
     def startSim(self):
         self.simStart = self.data.time
@@ -241,36 +251,169 @@ class quadrupedEnv(gym.Env):
     def close(self):
         mujoco.glfw.glfw.terminate()    
 
+    # find the reward
+    def findReward(self):
+        # Reward for forward velocity
+        fwd_velocity = (self.data.qvel[0]**2 + self.data.qvel[1]**2 + self.data.qvel[2]**2)**(0.5)
+
+        # Penalty for energy usage
+        control_penalty = np.sum(np.square(self.data.ctrl))  # Squared control effort
+        energy_penalty = -0.001 * control_penalty
+
+        # Reward for stability
+        roll, pitch, yaw = self.data.qpos[3:6]  # Assuming qpos[3:6] are orientation angles
+        orientation_penalty = -0.1 * (np.square(roll) + np.square(pitch))  # Penalize deviations from upright posture
+
+        # Reward for terrain adaptability
+        terrain_adapt_reward = 0
+        for i in range(self.model.nbody):
+            # Ensure this logic aligns with your contact model
+            if hasattr(self.data, 'contact') and len(self.data.contact) > i:
+                contact = self.data.contact[i]
+                if contact.geom1 or contact.geom2:  # Assuming contact indicates terrain interaction
+                    terrain_adapt_reward += 0.1  # Reward for maintaining contact
         
+        A = 4
+        B = 1
+        C = 8
+        D = 10
 
+        # Total reward
+        total_reward = A*fwd_velocity + B*energy_penalty + C*orientation_penalty + D*terrain_adapt_reward
 
+        return total_reward
+
+        
+
+def experiment(variant):
+    expl_env = NormalizedBoxEnv(quadrupedEnv())
+    eval_env = NormalizedBoxEnv(quadrupedEnv())
+    obs_dim = expl_env.observation_space.low.size
+ 
+    action_dim = eval_env.action_space.low.size
+
+    M = variant['layer_size']
+    qf1 = ConcatMlp(
+        input_size=obs_dim + action_dim,
+        output_size=1,
+        hidden_sizes=[M, M],
+    )
+    qf2 = ConcatMlp(
+        input_size=obs_dim + action_dim,
+        output_size=1,
+        hidden_sizes=[M, M],
+    )
+    target_qf1 = ConcatMlp(
+        input_size=obs_dim + action_dim,
+        output_size=1,
+        hidden_sizes=[M, M],
+    )
+    target_qf2 = ConcatMlp(
+        input_size=obs_dim + action_dim,
+        output_size=1,
+        hidden_sizes=[M, M],
+    )
+    policy = TanhGaussianPolicy(
+        obs_dim=obs_dim,
+        action_dim=action_dim,
+        hidden_sizes=[M, M],
+    )
+    eval_policy = MakeDeterministic(policy)
+    eval_path_collector = MdpPathCollector(
+        eval_env,
+        eval_policy,
+    )
+    expl_path_collector = MdpPathCollector(
+        expl_env,
+        policy,
+    )
+    replay_buffer = EnvReplayBuffer(
+        variant['replay_buffer_size'],
+        expl_env,
+
+    )
+    trainer = SACTrainer(
+        env=eval_env,
+        policy=policy,
+        qf1=qf1,
+        qf2=qf2,
+        target_qf1=target_qf1,
+        target_qf2=target_qf2,
+        **variant['trainer_kwargs']
+    )
+    algorithm = TorchBatchRLAlgorithm(
+        trainer=trainer,
+        exploration_env=expl_env,
+        evaluation_env=eval_env,
+        exploration_data_collector=expl_path_collector,
+        evaluation_data_collector=eval_path_collector,
+        replay_buffer=replay_buffer,
+        **variant['algorithm_kwargs']
+    )
+    algorithm.to(ptu.device)
+    algorithm.train()
 
-if __name__ == "__main__":
 
-    # # Load the model
-    # model_type = "MiDaS_small"  # Options: DPT_Large, DPT_Hybrid, MiDaS_small
-    # model = torch.hub.load("intel-isl/MiDaS", model_type)
 
 
 
-    env = quadrupedEnv()
-    simstart = env.startSim()
+if __name__ == "__main__":
+    # noinspection PyTypeChecker
+    variant = dict(
+        algorithm="SAC",
+        version="normal",
+        layer_size=256,
+        replay_buffer_size=int(1E4),
+        algorithm_kwargs=dict(
+            num_epochs=3000,
+            num_eval_steps_per_epoch=5000,
+            num_trains_per_train_loop=1000,
+            num_expl_steps_per_train_loop=1000,
+            min_num_steps_before_training=1000,
+            max_path_length=1000,
+            batch_size=256,
+        ),
+        trainer_kwargs=dict(
+            discount=0.99,
+            soft_target_tau=5e-3,
+            target_update_period=1,
+            policy_lr=3E-4,
+            qf_lr=3E-4,
+            reward_scale=1,
+            use_automatic_entropy_tuning=True,
+        ),
+    )
+    setup_logger('name-of-experiment', variant=variant)
+    # ptu.set_gpu_mode(True)  # optionally set the GPU (default=False)
+    experiment(variant)
+
+
+
+# if __name__ == "__main__":
+
+# # # Load the model
+# # model_type = "MiDaS_small"  # Options: DPT_Large, DPT_Hybrid, MiDaS_small
+# # model = torch.hub.load("intel-isl/MiDaS", model_type)
+
+
+
+#     env = quadrupedEnv()
     
-    while not mujoco.glfw.glfw.window_should_close(env.window_top):
-        simstart = env.startSim()
+#     while not mujoco.glfw.glfw.window_should_close(env.window_top):
+#         simstart = env.startSim()
 
-        torques = [0.1, 0.001, 0.001]
+#         torques = [0.1, 0.001, 0.001]
 
-        while (env.data.time - simstart < 10.0/60.0):
-            env.step()
+#         while (env.data.time - simstart < 10.0/60.0):
+#             env.step()
 
-        env.render()
-        if(env.pov_working):
-            # Display the height map
-            cv2.imshow("Height Map", env.depth_mujoco)
-            # cv2.imshow("Depth Map", env.depth_map)
+#         env.render()
+#         if(env.pov_working):
+#             # Display the height map
+#             cv2.imshow("Height Map", env.depth_mujoco)
+#             # cv2.imshow("Depth Map", env.depth_map)
 
-            if cv2.waitKey(1) == ord('q'):
-                break
-        
+#             if cv2.waitKey(1) == ord('q'):
+#                 break
+           
     
\ No newline at end of file
